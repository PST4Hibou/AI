{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "YOLO11 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Predict Drones"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Abstract\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† 1. Setup\n",
    "\n",
    "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.0 Importing Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install ultralytics markdown rich wrapt -q",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image as IPyImage\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import pandas as pd\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hashlib\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "ultralytics.checks()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Global Definitions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME_DIR = './datasets/new_dataset/'\n",
    "TRAINING_DATASET_DIRECTORY = DATASET_NAME_DIR + 'training/'\n",
    "VALIDATION_DATASET_DIRECTORY = DATASET_NAME_DIR + 'valid/'\n",
    "MODELS_DIRECTORY = './models/'\n",
    "RUNS_DIRECTORY = \"./runs\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìÇ 2. Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Acquire Dataset\n",
    "\n",
    "Download dataset from hugging face."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Data Structure Check\n",
    "\n",
    "##### Directory path validation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_image_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".jpg\") or f.endswith(\".JPEG\")]\n",
    "val_image_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".jpg\") or f.endswith(\".JPEG\")]\n",
    "\n",
    "print(f\"Number of images in training folder: {len(train_image_names)}\")\n",
    "print(f\"Number of images in valid folder: {len(val_image_names)}\")\n",
    "\n",
    "train_txt_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "val_txt_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "\n",
    "print(f\"\\nNumber of TXT files in train labels folder: {len(train_txt_names)}\")\n",
    "print(f\"Number of TXT files in val labels folder: {len(val_txt_names)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Duplicate files\n",
    "\n",
    "Check for duplicate images and labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths_to_check = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_image_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_image_names],\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_txt_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_txt_names],\n",
    "]\n",
    "\n",
    "\n",
    "def sha3_file(path, chunk_size=8192):\n",
    "    hash_sha3 = hashlib.sha3_256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            hash_sha3.update(chunk)\n",
    "    return hash_sha3.hexdigest()\n",
    "\n",
    "\n",
    "duplicates_array = []\n",
    "\n",
    "for path in paths_to_check:\n",
    "\n",
    "    # Build list of (hash, path)\n",
    "    pairs = [\n",
    "        (sha3_file(f), f)\n",
    "        for f in path\n",
    "    ]\n",
    "\n",
    "    # Group paths by hash\n",
    "    hash_map = defaultdict(list)\n",
    "    for h, p in pairs:\n",
    "        hash_map[h].append(p)\n",
    "\n",
    "    # Extract only duplicates\n",
    "    duplicates = {h: paths for h, paths in hash_map.items() if len(paths) > 1}\n",
    "    duplicates_array.append(duplicates)\n",
    "\n",
    "    # Print results\n",
    "    if duplicates:\n",
    "        print(\"Duplicate files found:\")\n",
    "        for h, paths in duplicates.items():\n",
    "            print(f\"Hash: {h}\")\n",
    "            for p in paths:\n",
    "                print(f\"  - {p}\")\n",
    "    else:\n",
    "        print(f\"No duplicate files found in the scanned directories.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### ‚ö†Ô∏èDelete duplicate files ‚ö†Ô∏è\n",
    "\n",
    "Delete for duplicate images and labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    if input(\"Files are going to be deleted. Write yes to continue.\") == 'yes':\n",
    "        for duplicates in duplicates_array:\n",
    "            for paths in duplicates.values():\n",
    "                for path in paths:\n",
    "                    os.remove(path)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Deletion aborted.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Check for orphelins txt file"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths_to_check = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_txt_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_txt_names],\n",
    "]\n",
    "\n",
    "orphelins_label = []\n",
    "\n",
    "for path_list in paths_to_check:\n",
    "    for p in path_list:\n",
    "\n",
    "        root, _ = os.path.splitext(p)\n",
    "\n",
    "        candidates = [\n",
    "            root + \".jpg\",\n",
    "            root + \".JPG\",\n",
    "            root + \".jpeg\",\n",
    "            root + \".JPEG\",\n",
    "            root + \".png\",\n",
    "            root + \".PNG\",\n",
    "        ]\n",
    "\n",
    "        if not any(os.path.isfile(c) for c in candidates):\n",
    "            orphelins_label.append(p)\n",
    "            print(f\"TXT file {p} does not belong to any image.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### ‚ö†Ô∏èDelete orphelin labels files ‚ö†Ô∏è\n",
    "\n",
    "Delete labels that don't belong to any images."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    if input(\"Files are going to be deleted. Write yes to continue.\") == 'yes':\n",
    "        for orphelin_path in orphelins_label:\n",
    "            os.remove(orphelin_path)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Deletion aborted.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Rename files\n",
    "\n",
    "Rename images and labels from 0 to n images."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN = TRAINING_DATASET_DIRECTORY\n",
    "VAL = VALIDATION_DATASET_DIRECTORY\n",
    "\n",
    "jpeg_exts = [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "\n",
    "tmp = os.path.join(DATASET_NAME_DIR, \"tmp\")\n",
    "\n",
    "\n",
    "def numeric_key(name):\n",
    "    nums = re.findall(r'\\d+', name)\n",
    "    return int(nums[0]) if nums else float('inf')\n",
    "\n",
    "\n",
    "def collect_images(folder):\n",
    "    return sorted(\n",
    "        [f for f in os.listdir(folder) if f.endswith(tuple(jpeg_exts))],\n",
    "        key=numeric_key\n",
    "    )\n",
    "\n",
    "\n",
    "def process(folder, start_i, out_dir):\n",
    "    files = collect_images(folder)\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    for f in files:\n",
    "        root, ext = os.path.splitext(f)\n",
    "\n",
    "        # find real existing image\n",
    "        image_path = None\n",
    "        for e in jpeg_exts:\n",
    "            p = os.path.join(folder, root + e)\n",
    "            if os.path.isfile(p):\n",
    "                image_path = p\n",
    "                break\n",
    "\n",
    "        if image_path is None:\n",
    "            print(\"Missing image for:\", f)\n",
    "            continue\n",
    "\n",
    "        label_path = os.path.join(folder, root + \".txt\")\n",
    "        if not os.path.isfile(label_path):\n",
    "            os.rename(image_path, os.path.join(out_dir, f\"{start_i}.jpg\"))\n",
    "            start_i += 1\n",
    "            continue\n",
    "\n",
    "        new_image = os.path.join(out_dir, f\"{start_i}.jpg\")\n",
    "        new_label = os.path.join(out_dir, f\"{start_i}.txt\")\n",
    "\n",
    "        # Move safely\n",
    "        os.rename(image_path, new_image)\n",
    "        os.rename(label_path, new_label)\n",
    "\n",
    "        start_i += 1\n",
    "\n",
    "    return start_i\n",
    "\n",
    "\n",
    "# === RUN ===\n",
    "\n",
    "i = 0\n",
    "i = process(TRAIN, i, tmp + '_train')\n",
    "i = process(VAL, i, tmp + '_valid')\n",
    "\n",
    "print(f\"DONE ‚Äî All files renamed safely into {DATASET_NAME_DIR}tmp_NAME\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set labels"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install torch==2.7.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install sam3 opencv-python pandas scikit-learn requests huggingface_hub ipywidgets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "from sam3.visualization_utils import plot_results\n",
    "from sam3 import build_sam3_image_model\n",
    "from huggingface_hub import login"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "login(os.getenv(\"HF_TOKEN\"))\n",
    "bpe_name = \"bpe_simple_vocab_16e6.txt.gz\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Load model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = build_sam3_image_model(bpe_path=os.path.join(MODELS_DIRECTORY, bpe_name))\n",
    "processor = Sam3Processor(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_path = f\"datasets/new_dataset/training/633.jpg\"\n",
    "prompt = \"drone\"\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "processor = Sam3Processor(model, confidence_threshold=confidence_threshold)\n",
    "inference_state = processor.set_image(image)\n",
    "\n",
    "processor.reset_all_prompts(inference_state)\n",
    "inference_state = processor.set_text_prompt(state=inference_state, prompt=prompt)\n",
    "img0 = Image.open(image_path)\n",
    "plot_results(img0, inference_state)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Settings"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labelize_overwrite_label: bool = True\n",
    "labelize_prompt: str = 'drone'\n",
    "labelize_confidence_threshold: float = 0.62\n",
    "labelize_save_inference: bool = False\n",
    "labelize_drone_class = 0\n",
    "labelize_output_label_file_directory = os.path.join(DATASET_NAME_DIR, 'new_labels')\n",
    "labelize_output_label_file_errors = os.path.join(labelize_output_label_file_directory, 'errors.txt')\n",
    "labelize_output_label_file_success = os.path.join(labelize_output_label_file_directory, 'success.txt')\n",
    "\n",
    "paths_to_labelize = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_image_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_image_names],\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.makedirs(labelize_output_label_file_directory, exist_ok=True)\n",
    "\n",
    "image_failed_labelize = []\n",
    "\n",
    "for paths in paths_to_labelize:\n",
    "    for image_path in paths:\n",
    "        root, ext = os.path.splitext(image_path)\n",
    "        root_label_name = root.split(\"/\")[-1]\n",
    "        current_label_path = root + \".txt\"\n",
    "        saved_label_path = os.path.join(labelize_output_label_file_directory, root_label_name) + \".txt\"\n",
    "\n",
    "        if os.path.isfile(current_label_path) and not labelize_overwrite_label:\n",
    "            continue\n",
    "\n",
    "        if os.path.isfile(saved_label_path) and not labelize_overwrite_label:\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        if image.mode != \"RGB\":\n",
    "            with open(labelize_output_label_file_errors, \"a\") as f:\n",
    "                image_failed_labelize.append(image_path)\n",
    "                f.write(f\"{image_path} is not RGB.\\n\")\n",
    "            continue\n",
    "        width, height = image.size\n",
    "\n",
    "        # Run SAM3 processor\n",
    "        processor = Sam3Processor(model, confidence_threshold=labelize_confidence_threshold)\n",
    "        inference_state = processor.set_image(image)\n",
    "        processor.reset_all_prompts(inference_state)\n",
    "        inference_state = processor.set_text_prompt(state=inference_state, prompt=labelize_prompt)\n",
    "\n",
    "        # --- Save YOLO labels ---\n",
    "        bboxes = inference_state.get(\"boxes\", None)  # fixed\n",
    "\n",
    "        if bboxes is None or len(bboxes) == 0:\n",
    "            # print(f\"No detections for {image_path}\")\n",
    "            image_failed_labelize.append(image_path)\n",
    "            with open(labelize_output_label_file_errors, \"a\") as f:\n",
    "                f.write(f\"No detections for {image_path}\\n\")\n",
    "            continue\n",
    "\n",
    "        yolo_lines = []\n",
    "        for box in bboxes:\n",
    "            x_min, y_min, x_max, y_max = box  # SAM3 gives XYXY\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            bbox_width = x_max - x_min\n",
    "            bbox_height = y_max - y_min\n",
    "\n",
    "            cx = (x_min + bbox_width / 2) / width\n",
    "            cy = (y_min + bbox_height / 2) / height\n",
    "\n",
    "            nw = bbox_width / width\n",
    "            nh = bbox_height / height\n",
    "\n",
    "            yolo_lines.append(\n",
    "                f\"{labelize_drone_class} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\"\n",
    "            )\n",
    "\n",
    "        with open(saved_label_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "        with open(labelize_output_label_file_success, \"a\") as f:\n",
    "            f.write(f\"Saved YOLO labels: {saved_label_path}\\n\")\n",
    "\n",
    "    with open(labelize_output_label_file_success, 'r') as fp:\n",
    "        nb_lines = len(fp.readlines())\n",
    "        print(f\"Successfully procedded files: {nb_lines} out of {len(paths)} for {paths[0][0]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    if input(\"Files are going to be deleted. Write yes to continue.\") == 'yes':\n",
    "        for image_path in image_failed_labelize:\n",
    "            os.remove(image_path)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Deletion aborted.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Check\n",
    "\n",
    "Load N random images and show rectangle round the drone."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_image_with_boxes(image_path, label_path):\n",
    "    \"\"\"Returns a PIL image with YOLO bounding boxes drawn.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    w, h = img.size\n",
    "\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            cls, xc, yc, bw, bh = map(float, line.split())\n",
    "\n",
    "            # YOLO normalized ‚Üí pixel coordinates\n",
    "            x_center = xc * w\n",
    "            y_center = yc * h\n",
    "            box_width = bw * w\n",
    "            box_height = bh * h\n",
    "\n",
    "            x1 = x_center - box_width / 2\n",
    "            y1 = y_center - box_height / 2\n",
    "            x2 = x_center + box_width / 2\n",
    "            y2 = y_center + box_height / 2\n",
    "\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "            draw.text((x1, y1), f\"{int(cls)}\", fill=\"red\")\n",
    "\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = 48  # number of random samples\n",
    "cols = 4\n",
    "\n",
    "# list all images\n",
    "image_paths = [p for p in os.listdir(TRAINING_DATASET_DIRECTORY) if p.lower().endswith((\".jpg\", \".png\"))]\n",
    "sampled_images = random.sample(image_paths, min(N, len(image_paths)))\n",
    "\n",
    "# -------- DISPLAY GRID -------- #\n",
    "\n",
    "rows = math.ceil(len(sampled_images) / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img_name in zip(axes, sampled_images):\n",
    "    img_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name)\n",
    "    label_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "    img = load_image_with_boxes(img_path, label_path)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(img_name, fontsize=8)\n",
    "\n",
    "# turn off unused axes\n",
    "for ax in axes[len(sampled_images):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚öôÔ∏è 3. Training\n",
    "\n",
    "Purpose: Handle model setup and training configuration."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Model Selection"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "YOLO_MODELS = {\n",
    "    \"nano\": \"yolo11n.pt\",\n",
    "    \"small\": \"yolo11s.pt\",\n",
    "    \"medium\": \"yolo11m.pt\",\n",
    "    \"large\": \"yolo11l.pt\",\n",
    "    \"xlarge\": \"yolo11x.pt\",\n",
    "}\n",
    "\n",
    "selected_size = \"nano\"\n",
    "model = YOLO(MODELS_DIRECTORY + YOLO_MODELS[selected_size])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Training Configuration\n",
    "Define hyperparameters (epochs, batch size, image size)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train=os.path.join('../../', TRAINING_DATASET_DIRECTORY),\n",
    "    val=os.path.join('../../', VALIDATION_DATASET_DIRECTORY),\n",
    "    nc=1,\n",
    "    names=['drone']\n",
    ")\n",
    "\n",
    "data_config_path = os.path.join(DATASET_NAME_DIR, 'data.yaml')\n",
    "\n",
    "with open(data_config_path, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "\n",
    "%cat \"$data_config_path\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = {\n",
    "    'data': data_config_path,\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'lr0': 0.001,\n",
    "    'optimizer': 'SGD',\n",
    "    'project': RUNS_DIRECTORY\n",
    "}\n",
    "\n",
    "train_config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Parameter breakdown:**\n",
    "\n",
    "- **train**: Executes the YOLOv11x training pipeline.\n",
    "- **model**=yolov11x.pt: Uses pre-trained YOLOv11x weights as initialization.\n",
    "- **data**=/content/data.yaml: Specifies the dataset configuration file.\n",
    "- **imgsz**=640: Sets input resolution to enhance small-object detection.\n",
    "- **lr0**=0.001: Sets the learing rate for each training step.\n",
    "- **epochs**=32: Defines the number of training cycles over the dataset.\n",
    "- **batch**=16: Sets the batch size for each training step.\n",
    "- **device**=0: Allocates GPU device 0 for training.\n",
    "- **optimizer**=AdamW: As default, AdamW optimization algorithm utilized."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Run Training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = model.train(**train_config)\n",
    "plot_results(os.path.join(RUNS_DIRECTORY, \"/train/results.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 Result of training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(IPyImage(filename=os.path.join(RUNS_DIRECTORY, \"/train/results.png\")))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_paths = []\n",
    "\n",
    "for root, _, files in os.walk(os.path.join(RUNS_DIRECTORY, \"train\")):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\")):\n",
    "            results_paths.append(os.path.join(root, f))\n",
    "results_paths = sorted(results_paths)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for path in results_paths:\n",
    "    image = np.array(Image.open(path))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5 Evaluate Model\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = model.val()\n",
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.6 Compare with previous trains"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "saved_train_path = \"./saved_trains\"\n",
    "\n",
    "# List all folders in the saved_train_path\n",
    "folders_results = [dir for dir in os.listdir(saved_train_path) if os.path.isdir(os.path.join(saved_train_path, dir))]\n",
    "\n",
    "# Convert folder names to datetime objects for sorting\n",
    "folders_results_sorted = sorted(\n",
    "    folders_results,\n",
    "    key=lambda x: datetime.strptime(x, \"%d-%m-%Y_%H:%M:%S\"),\n",
    "    reverse=True  # latest first\n",
    ")\n",
    "\n",
    "# Take the last 2 trainings by date\n",
    "last_two_folders = folders_results_sorted[:2]\n",
    "\n",
    "# Dictionary to store the last row of each folder\n",
    "results_data = {}\n",
    "\n",
    "for folder in last_two_folders:\n",
    "    path = os.path.join(saved_train_path, folder)\n",
    "    results_csv = os.path.join(path, \"results.csv\")\n",
    "\n",
    "    if os.path.exists(results_csv):\n",
    "        df = pd.read_csv(results_csv)\n",
    "        # Get the last row as a dictionary\n",
    "        last_row = df.iloc[-1].to_dict()\n",
    "\n",
    "        # Compute a custom YOLO train score\n",
    "        score = (\n",
    "            last_row['metrics/mAP50-95(B)'] * 0.7 +\n",
    "            last_row['metrics/recall(B)'] * 0.2 -\n",
    "            last_row['val/box_loss'] * 0.1\n",
    "        )\n",
    "\n",
    "        # Add the score to the dictionary\n",
    "        last_row['train_score'] = score\n",
    "\n",
    "        results_data[folder] = last_row\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "summary_df = pd.DataFrame.from_dict(results_data, orient='index')\n",
    "summary_df.reset_index(inplace=True)\n",
    "summary_df.rename(columns={'index': 'folder'}, inplace=True)\n",
    "\n",
    "# Sort by train_score if desired\n",
    "best_train = summary_df.sort_values(by='train_score', ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# üîç 4. Prediction & Visualization\n",
    "\n",
    "Purpose: Evaluate results qualitatively and quantitatively.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Run Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_path = os.path.join(RUNS_DIRECTORY, \"train/weights/best.pt\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "custom_model = YOLO(best_path)\n",
    "!rm -rf ./runs/predict\n",
    "preds = custom_model.predict(VALIDATION_DATASET_DIRECTORY, save=True, project=RUNS_DIRECTORY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Result of Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = custom_model.predict(VALIDATION_DATASET_DIRECTORY, conf=0.2)\n",
    "print(len(results))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3 Visualize Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_paths = []\n",
    "\n",
    "for root, _, files in os.walk(os.path.join(RUNS_DIRECTORY, \"predict\")):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            predictions_paths.append(os.path.join(root, f))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = 4\n",
    "max_images_preview = -1\n",
    "rows = math.ceil(len(predictions_paths) / cols)\n",
    "\n",
    "plt.figure(figsize=(cols * 3, rows * 2))  # dynamic size\n",
    "for i, path in enumerate(predictions_paths):\n",
    "    if max_images_preview != -1 and max_images_preview < len(predictions_paths):\n",
    "        break\n",
    "    img = Image.open(path)\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìä 5. Analysis & Improvements\n",
    "Purpose: Interpret and iterate."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Metrics Review"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.box.map, metrics.box.map50, metrics.box.map75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Error Analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.confusion_matrix.plot()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Compare with previous trains"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ‚úÖ 6. Export & Deployment"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 Save results"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source = os.path.join(RUNS_DIRECTORY, \"train\")\n",
    "saved_success_file_name = \".saved.success\"\n",
    "\n",
    "check_for_file = os.path.isfile(os.path.join(source, saved_success_file_name))\n",
    "\n",
    "if check_for_file:\n",
    "    print(\"Training already saved. If you want to save it again, delete the .saved.success file.\")\n",
    "else:\n",
    "    now = datetime.now().strftime('%d-%m-%Y_%H:%M:%S')\n",
    "    destination = \"./saved_trains/\" + now\n",
    "\n",
    "    shutil.copytree(source, destination, dirs_exist_ok=True)\n",
    "\n",
    "    train_config_path = os.path.join(destination, 'train_config.json')\n",
    "    with open(train_config_path, 'w') as outfile:\n",
    "        yaml.dump(json.dumps(train_config), outfile, default_flow_style=True)\n",
    "\n",
    "    saved_file = os.path.join(source, '.saved.success')\n",
    "\n",
    "    with open(saved_file, \"a\") as f:\n",
    "        f.write(now)\n",
    "    print(\"Training saved successfully.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
