{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "YOLO11 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Predict Drones"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Abstract\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† 1. Setup\n",
    "\n",
    "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.0 Importing Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install ultralytics -q",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image as IPyImage\n",
    "from ultralytics.utils.plotting import plot_results\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "ultralytics.checks()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Global Definitions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME_DIR = './datasets/drone_dataset/'\n",
    "TRAINING_DATASET_DIRECTORY = DATASET_NAME_DIR + 'training/'\n",
    "VALIDATION_DATASET_DIRECTORY = DATASET_NAME_DIR + 'valid/'\n",
    "MODELS_DIRECTORY = './models/'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìÇ 2. Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Acquire Dataset\n",
    "\n",
    "Download dataset from hugging face."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Data Structure Check\n",
    "\n",
    "##### Directory path validation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_image_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".jpg\")]\n",
    "val_image_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".jpg\")]\n",
    "\n",
    "print(f\"Number of images in training folder: {len(train_image_names)}\")\n",
    "print(f\"Number of images in valid folder: {len(val_image_names)}\")\n",
    "\n",
    "train_txt_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "val_txt_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "\n",
    "print(f\"\\nNumber of TXT files in train labels folder: {len(train_txt_names)}\")\n",
    "print(f\"Number of TXT files in val labels folder: {len(val_txt_names)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Duplicate files\n",
    "\n",
    "Check for duplicate images and labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths_to_check = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_image_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_image_names],\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_txt_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_txt_names],\n",
    "]\n",
    "\n",
    "\n",
    "def sha3_file(path, chunk_size=8192):\n",
    "    hash_sha3 = hashlib.sha3_256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            hash_sha3.update(chunk)\n",
    "    return hash_sha3.hexdigest()\n",
    "\n",
    "\n",
    "for path in paths_to_check:\n",
    "\n",
    "    # Build list of (hash, path)\n",
    "    pairs = [\n",
    "        (sha3_file(f), f)\n",
    "        for f in path\n",
    "    ]\n",
    "\n",
    "    # Group paths by hash\n",
    "    hash_map = defaultdict(list)\n",
    "    for h, p in pairs:\n",
    "        hash_map[h].append(p)\n",
    "\n",
    "    # Extract only duplicates\n",
    "    duplicates = {h: paths for h, paths in hash_map.items() if len(paths) > 1}\n",
    "\n",
    "    # Print results\n",
    "    if duplicates:\n",
    "        print(\"Duplicate files found:\")\n",
    "        for h, paths in duplicates.items():\n",
    "            print(f\"Hash: {h}\")\n",
    "            for p in paths:\n",
    "                print(f\"  - {p}\")\n",
    "    else:\n",
    "        print(f\"No duplicate files in {path[0]}.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Check\n",
    "\n",
    "Load N random images and show rectangle round the drone."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_image_with_boxes(image_path, label_path):\n",
    "    \"\"\"Returns a PIL image with YOLO bounding boxes drawn.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    w, h = img.size\n",
    "\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            cls, xc, yc, bw, bh = map(float, line.split())\n",
    "\n",
    "            # YOLO normalized ‚Üí pixel coordinates\n",
    "            x_center = xc * w\n",
    "            y_center = yc * h\n",
    "            box_width = bw * w\n",
    "            box_height = bh * h\n",
    "\n",
    "            x1 = x_center - box_width / 2\n",
    "            y1 = y_center - box_height / 2\n",
    "            x2 = x_center + box_width / 2\n",
    "            y2 = y_center + box_height / 2\n",
    "\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "            draw.text((x1, y1), f\"{int(cls)}\", fill=\"red\")\n",
    "\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = 48  # number of random samples\n",
    "cols = 4\n",
    "\n",
    "# list all images\n",
    "image_paths = [p for p in os.listdir(TRAINING_DATASET_DIRECTORY) if p.lower().endswith((\".jpg\", \".png\"))]\n",
    "sampled_images = random.sample(image_paths, min(N, len(image_paths)))\n",
    "\n",
    "# -------- DISPLAY GRID -------- #\n",
    "\n",
    "rows = math.ceil(len(sampled_images) / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img_name in zip(axes, sampled_images):\n",
    "    img_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name)\n",
    "    label_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "    img = load_image_with_boxes(img_path, label_path)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(img_name, fontsize=8)\n",
    "\n",
    "# turn off unused axes\n",
    "for ax in axes[len(sampled_images):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚öôÔ∏è 3. Training\n",
    "\n",
    "Purpose: Handle model setup and training configuration."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Model Selection"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "YOLO_MODELS = {\n",
    "    \"nano\": \"yolo11n.pt\",\n",
    "    \"small\": \"yolo11s.pt\",\n",
    "    \"medium\": \"yolo11m.pt\",\n",
    "    \"large\": \"yolo11l.pt\",\n",
    "    \"xlarge\": \"yolo11x.pt\",\n",
    "}\n",
    "\n",
    "selected_size = \"nano\"\n",
    "model = YOLO(MODELS_DIRECTORY + YOLO_MODELS[selected_size])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Training Configuration\n",
    "Define hyperparameters (epochs, batch size, image size)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train=os.path.join('../../', TRAINING_DATASET_DIRECTORY),\n",
    "    val=os.path.join('../../', VALIDATION_DATASET_DIRECTORY),\n",
    "    nc=1,\n",
    "    names=['drone']\n",
    ")\n",
    "\n",
    "data_config_path = os.path.join(DATASET_NAME_DIR, 'data.yaml')\n",
    "\n",
    "with open(data_config_path, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "\n",
    "%cat \"$data_config_path\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = {\n",
    "    'data': data_config_path,\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'lr0': 0.01,\n",
    "    'optimizer': 'SGD',\n",
    "    'project': './runs'\n",
    "}\n",
    "\n",
    "train_config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Parameter breakdown:**\n",
    "\n",
    "- **train**: Executes the YOLOv11x training pipeline.\n",
    "- **model**=yolov11x.pt: Uses pre-trained YOLOv11x weights as initialization.\n",
    "- **data**=/content/data.yaml: Specifies the dataset configuration file.\n",
    "- **imgsz**=640: Sets input resolution to enhance small-object detection.\n",
    "- **lr0**=0.001: Sets the learing rate for each training step.\n",
    "- **epochs**=32: Defines the number of training cycles over the dataset.\n",
    "- **batch**=16: Sets the batch size for each training step.\n",
    "- **device**=0: Allocates GPU device 0 for training.\n",
    "- **optimizer**=AdamW: As default, AdamW optimization algorithm utilized."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Run Training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = model.train(**train_config)\n",
    "plot_results(\"./runs/train/results.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 Result of training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(IPyImage(filename=os.path.join(\"./runs/train/results.png\")))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_paths = []\n",
    "\n",
    "for root, _, files in os.walk(\"./runs/train\"):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\")):\n",
    "            results_paths.append(os.path.join(root, f))\n",
    "results_paths = sorted(results_paths)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for path in results_paths:\n",
    "    image = Image.open(path)\n",
    "    image = np.array(image)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5 Evaluate Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = model.val()\n",
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# üîç 4. Prediction & Visualization\n",
    "\n",
    "Purpose: Evaluate results qualitatively and quantitatively.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Run Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_path = './runs/train/weights/best.pt'",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "custom_model = YOLO(best_path)\n",
    "!rm -rf ./runs/predict\n",
    "preds = custom_model.predict(VALIDATION_DATASET_DIRECTORY, save=True, project=\"./runs\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Result of Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = custom_model.predict(VALIDATION_DATASET_DIRECTORY, conf=0.2)\n",
    "print(len(results))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3 Visualize Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_paths = []\n",
    "\n",
    "for root, _, files in os.walk(\"./runs/predict\"):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            predictions_paths.append(os.path.join(root, f))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = 4\n",
    "max_images_preview = -1\n",
    "rows = math.ceil(len(predictions_paths) / cols)\n",
    "\n",
    "plt.figure(figsize=(cols * 3, rows * 2))  # dynamic size\n",
    "for i, path in enumerate(predictions_paths):\n",
    "    if max_images_preview != -1 and max_images_preview < len(predictions_paths):\n",
    "        break\n",
    "    img = Image.open(path)\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìä 5. Analysis & Improvements\n",
    "Purpose: Interpret and iterate."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Metrics Review"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.box.map, metrics.box.map50, metrics.box.map75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Error Analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.confusion_matrix.plot()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ‚úÖ 6. Export & Deployment"
  }
 ]
}
