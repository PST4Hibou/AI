{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "YOLO11 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and Predict Drones"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Abstract\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß† 1. Setup\n",
    "\n",
    "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.0 Importing Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "from matplotlib.font_manager import json_dump\n",
    "!pip install ultralytics -q"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image as IPyImage\n",
    "from ultralytics.utils.plotting import plot_results\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hashlib\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "ultralytics.checks()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Global Definitions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME_DIR = './datasets/new_dataset/'\n",
    "TRAINING_DATASET_DIRECTORY = DATASET_NAME_DIR + 'training/'\n",
    "VALIDATION_DATASET_DIRECTORY = DATASET_NAME_DIR + 'valid/'\n",
    "MODELS_DIRECTORY = './models/'\n",
    "RUNS_DIRECTORY = \"./runs\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üìÇ 2. Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Acquire Dataset\n",
    "\n",
    "Download dataset from hugging face."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Data Structure Check\n",
    "\n",
    "##### Directory path validation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_image_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".jpg\") or f.endswith(\".JPEG\")]\n",
    "val_image_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".jpg\") or f.endswith(\".JPEG\")]\n",
    "\n",
    "print(f\"Number of images in training folder: {len(train_image_names)}\")\n",
    "print(f\"Number of images in valid folder: {len(val_image_names)}\")\n",
    "\n",
    "train_txt_names = [f for f in os.listdir(TRAINING_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "val_txt_names = [f for f in os.listdir(VALIDATION_DATASET_DIRECTORY) if f.endswith(\".txt\")]\n",
    "\n",
    "print(f\"\\nNumber of TXT files in train labels folder: {len(train_txt_names)}\")\n",
    "print(f\"Number of TXT files in val labels folder: {len(val_txt_names)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Duplicate files\n",
    "\n",
    "Check for duplicate images and labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths_to_check = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_image_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_image_names],\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_txt_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_txt_names],\n",
    "]\n",
    "\n",
    "\n",
    "def sha3_file(path, chunk_size=8192):\n",
    "    hash_sha3 = hashlib.sha3_256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            hash_sha3.update(chunk)\n",
    "    return hash_sha3.hexdigest()\n",
    "\n",
    "\n",
    "duplicates_array = []\n",
    "\n",
    "for path in paths_to_check:\n",
    "\n",
    "    # Build list of (hash, path)\n",
    "    pairs = [\n",
    "        (sha3_file(f), f)\n",
    "        for f in path\n",
    "    ]\n",
    "\n",
    "    # Group paths by hash\n",
    "    hash_map = defaultdict(list)\n",
    "    for h, p in pairs:\n",
    "        hash_map[h].append(p)\n",
    "\n",
    "    # Extract only duplicates\n",
    "    duplicates = {h: paths for h, paths in hash_map.items() if len(paths) > 1}\n",
    "    duplicates_array.append(duplicates)\n",
    "\n",
    "    # Print results\n",
    "    if duplicates:\n",
    "        print(\"Duplicate files found:\")\n",
    "        for h, paths in duplicates.items():\n",
    "            print(f\"Hash: {h}\")\n",
    "            for p in paths:\n",
    "                print(f\"  - {p}\")\n",
    "    else:\n",
    "        print(f\"No duplicate files found in the scanned directories.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### ‚ö†Ô∏èDelete duplicate files ‚ö†Ô∏è\n",
    "\n",
    "Delete for duplicate images and labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    if input(\"Files are going to be deleted. Write yes to continue.\") == 'yes':\n",
    "        for duplicates in duplicates_array:\n",
    "            for paths in duplicates.values():\n",
    "                for path in paths:\n",
    "                    os.remove(path)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Deletion aborted.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Check for orphelins txt file"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths_to_check = [\n",
    "    [os.path.join(TRAINING_DATASET_DIRECTORY, f) for f in train_txt_names],\n",
    "    [os.path.join(VALIDATION_DATASET_DIRECTORY, f) for f in val_txt_names],\n",
    "]\n",
    "\n",
    "orphelins_label = []\n",
    "\n",
    "for path_list in paths_to_check:\n",
    "    for p in path_list:\n",
    "\n",
    "        root, _ = os.path.splitext(p)\n",
    "\n",
    "        candidates = [\n",
    "            root + \".jpg\",\n",
    "            root + \".JPG\",\n",
    "            root + \".jpeg\",\n",
    "            root + \".JPEG\",\n",
    "            root + \".png\",\n",
    "            root + \".PNG\",\n",
    "        ]\n",
    "\n",
    "        if not any(os.path.isfile(c) for c in candidates):\n",
    "            orphelins_label.append(p)\n",
    "            print(f\"TXT file {p} does not belong to any image.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### ‚ö†Ô∏èDelete orphelin labels files ‚ö†Ô∏è\n",
    "\n",
    "Delete labels that don't belong to any images."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    if input(\"Files are going to be deleted. Write yes to continue.\") == 'yes':\n",
    "        for orphelin_path in orphelins_label:\n",
    "            os.remove(orphelin_path)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Deletion aborted.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Rename files\n",
    "\n",
    "Rename images and labels from 0 to n images."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN = TRAINING_DATASET_DIRECTORY\n",
    "VAL = VALIDATION_DATASET_DIRECTORY\n",
    "\n",
    "jpeg_exts = [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "\n",
    "tmp = os.path.join(DATASET_NAME_DIR, \"tmp\")\n",
    "\n",
    "\n",
    "def numeric_key(name):\n",
    "    nums = re.findall(r'\\d+', name)\n",
    "    return int(nums[0]) if nums else float('inf')\n",
    "\n",
    "\n",
    "def collect_images(folder):\n",
    "    return sorted(\n",
    "        [f for f in os.listdir(folder) if f.endswith(tuple(jpeg_exts))],\n",
    "        key=numeric_key\n",
    "    )\n",
    "\n",
    "\n",
    "def process(folder, start_i, out_dir):\n",
    "    files = collect_images(folder)\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    for f in files:\n",
    "        root, ext = os.path.splitext(f)\n",
    "\n",
    "        # find real existing image\n",
    "        image_path = None\n",
    "        for e in jpeg_exts:\n",
    "            p = os.path.join(folder, root + e)\n",
    "            if os.path.isfile(p):\n",
    "                image_path = p\n",
    "                break\n",
    "\n",
    "        if image_path is None:\n",
    "            print(\"Missing image for:\", f)\n",
    "            continue\n",
    "\n",
    "        label_path = os.path.join(folder, root + \".txt\")\n",
    "        if not os.path.isfile(label_path):\n",
    "            os.rename(image_path, os.path.join(out_dir, f\"{start_i}.jpg\"))\n",
    "            start_i += 1\n",
    "            continue\n",
    "\n",
    "        new_image = os.path.join(out_dir, f\"{start_i}.jpg\")\n",
    "        new_label = os.path.join(out_dir, f\"{start_i}.txt\")\n",
    "\n",
    "        # Move safely\n",
    "        os.rename(image_path, new_image)\n",
    "        os.rename(label_path, new_label)\n",
    "\n",
    "        start_i += 1\n",
    "\n",
    "    return start_i\n",
    "\n",
    "\n",
    "# === RUN ===\n",
    "\n",
    "i = 0\n",
    "i = process(TRAIN, i, tmp + '_train')\n",
    "i = process(VAL, i, tmp + '_valid')\n",
    "\n",
    "print(f\"DONE ‚Äî All files renamed safely into {DATASET_NAME_DIR}tmp_NAME\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Check\n",
    "\n",
    "Load N random images and show rectangle round the drone."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_image_with_boxes(image_path, label_path):\n",
    "    \"\"\"Returns a PIL image with YOLO bounding boxes drawn.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    w, h = img.size\n",
    "\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            cls, xc, yc, bw, bh = map(float, line.split())\n",
    "\n",
    "            # YOLO normalized ‚Üí pixel coordinates\n",
    "            x_center = xc * w\n",
    "            y_center = yc * h\n",
    "            box_width = bw * w\n",
    "            box_height = bh * h\n",
    "\n",
    "            x1 = x_center - box_width / 2\n",
    "            y1 = y_center - box_height / 2\n",
    "            x2 = x_center + box_width / 2\n",
    "            y2 = y_center + box_height / 2\n",
    "\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "            draw.text((x1, y1), f\"{int(cls)}\", fill=\"red\")\n",
    "\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = 48  # number of random samples\n",
    "cols = 4\n",
    "\n",
    "# list all images\n",
    "image_paths = [p for p in os.listdir(TRAINING_DATASET_DIRECTORY) if p.lower().endswith((\".jpg\", \".png\"))]\n",
    "sampled_images = random.sample(image_paths, min(N, len(image_paths)))\n",
    "\n",
    "# -------- DISPLAY GRID -------- #\n",
    "\n",
    "rows = math.ceil(len(sampled_images) / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img_name in zip(axes, sampled_images):\n",
    "    img_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name)\n",
    "    label_path = os.path.join(TRAINING_DATASET_DIRECTORY, img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "    img = load_image_with_boxes(img_path, label_path)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(img_name, fontsize=8)\n",
    "\n",
    "# turn off unused axes\n",
    "for ax in axes[len(sampled_images):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚öôÔ∏è 3. Training\n",
    "\n",
    "Purpose: Handle model setup and training configuration."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Model Selection"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "YOLO_MODELS = {\n",
    "    \"nano\": \"yolo11n.pt\",\n",
    "    \"small\": \"yolo11s.pt\",\n",
    "    \"medium\": \"yolo11m.pt\",\n",
    "    \"large\": \"yolo11l.pt\",\n",
    "    \"xlarge\": \"yolo11x.pt\",\n",
    "}\n",
    "\n",
    "selected_size = \"nano\"\n",
    "model = YOLO(MODELS_DIRECTORY + YOLO_MODELS[selected_size])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Training Configuration\n",
    "Define hyperparameters (epochs, batch size, image size)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train=os.path.join('../../', TRAINING_DATASET_DIRECTORY),\n",
    "    val=os.path.join('../../', VALIDATION_DATASET_DIRECTORY),\n",
    "    nc=1,\n",
    "    names=['drone']\n",
    ")\n",
    "\n",
    "data_config_path = os.path.join(DATASET_NAME_DIR, 'data.yaml')\n",
    "\n",
    "with open(data_config_path, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "\n",
    "%cat \"$data_config_path\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = {\n",
    "    'data': data_config_path,\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'lr0': 0.001,\n",
    "    'optimizer': 'SGD',\n",
    "    'project': RUNS_DIRECTORY\n",
    "}\n",
    "\n",
    "train_config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Parameter breakdown:**\n",
    "\n",
    "- **train**: Executes the YOLOv11x training pipeline.\n",
    "- **model**=yolov11x.pt: Uses pre-trained YOLOv11x weights as initialization.\n",
    "- **data**=/content/data.yaml: Specifies the dataset configuration file.\n",
    "- **imgsz**=640: Sets input resolution to enhance small-object detection.\n",
    "- **lr0**=0.001: Sets the learing rate for each training step.\n",
    "- **epochs**=32: Defines the number of training cycles over the dataset.\n",
    "- **batch**=16: Sets the batch size for each training step.\n",
    "- **device**=0: Allocates GPU device 0 for training.\n",
    "- **optimizer**=AdamW: As default, AdamW optimization algorithm utilized."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Run Training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = model.train(**train_config)\n",
    "plot_results(os.path.join(RUNS_DIRECTORY, \"/train/results.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 Result of training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(IPyImage(filename=os.path.join(RUNS_DIRECTORY, \"/train/results.png\")))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_paths = []\n",
    "\n",
    "for root, _, files in os.walk(os.path.join(RUNS_DIRECTORY, \"train\")):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\")):\n",
    "            results_paths.append(os.path.join(root, f))\n",
    "results_paths = sorted(results_paths)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for path in results_paths:\n",
    "    image = np.array(Image.open(path))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5 Evaluate Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = model.val()\n",
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# üîç 4. Prediction & Visualization\n",
    "\n",
    "Purpose: Evaluate results qualitatively and quantitatively.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Run Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_path = os.path.join(RUNS_DIRECTORY, \"train/weights/best.pt\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "custom_model = YOLO(best_path)\n",
    "!rm -rf ./runs/predict\n",
    "preds = custom_model.predict(VALIDATION_DATASET_DIRECTORY, save=True, project=RUNS_DIRECTORY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Result of Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = custom_model.predict(VALIDATION_DATASET_DIRECTORY, conf=0.2)\n",
    "print(len(results))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3 Visualize Predictions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_paths = []\n",
    "\n",
    "for root, _, files in os.walk(os.path.join(RUNS_DIRECTORY, \"predict\")):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            predictions_paths.append(os.path.join(root, f))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = 4\n",
    "max_images_preview = -1\n",
    "rows = math.ceil(len(predictions_paths) / cols)\n",
    "\n",
    "plt.figure(figsize=(cols * 3, rows * 2))  # dynamic size\n",
    "for i, path in enumerate(predictions_paths):\n",
    "    if max_images_preview != -1 and max_images_preview < len(predictions_paths):\n",
    "        break\n",
    "    img = Image.open(path)\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìä 5. Analysis & Improvements\n",
    "Purpose: Interpret and iterate."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Metrics Review"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.box.map, metrics.box.map50, metrics.box.map75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Error Analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics.confusion_matrix.plot()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Compare with previous trains"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ‚úÖ 6. Export & Deployment"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 Save results"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source = os.path.join(RUNS_DIRECTORY, \"train\")\n",
    "saved_success_file_name = \".saved.success\"\n",
    "\n",
    "check_for_file = os.path.isfile(os.path.join(source, saved_success_file_name))\n",
    "\n",
    "if check_for_file:\n",
    "    print(\"Training already saved. If you want to save it again, delete the .saved.success file.\")\n",
    "else:\n",
    "    now = datetime.datetime.now().strftime('%d-%m-%Y_%H:%M:%S')\n",
    "    destination = \"./saved_trains/\" + now\n",
    "\n",
    "    shutil.copytree(source, destination, dirs_exist_ok=True)\n",
    "\n",
    "    train_config_path = os.path.join(destination, 'train_config.json')\n",
    "    with open(train_config_path, 'w') as outfile:\n",
    "        yaml.dump(json.dumps(train_config), outfile, default_flow_style=True)\n",
    "\n",
    "    saved_file = os.path.join(source, '.saved.success')\n",
    "\n",
    "    with open(saved_file, \"a\") as f:\n",
    "      f.write(now)\n",
    "    print(\"Training saved successfully.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
