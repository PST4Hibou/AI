{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T11:35:11.217448Z",
     "start_time": "2025-10-15T11:35:09.724306Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_from_disk, DatasetDict, load_dataset\n",
    "import torchaudio\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 12\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T09:10:44.213194Z",
     "start_time": "2025-10-15T09:10:42.258068Z"
    }
   },
   "cell_type": "code",
   "source": "ds = load_dataset(\"Usernameeeeee/df_462700_2\")",
   "id": "df456de17baaf3af",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T07:41:05.904554Z",
     "start_time": "2025-10-15T07:41:05.901528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LABELS = ds[\"train\"].features[\"label\"]\n",
    "\n",
    "if not isinstance(ds, DatasetDict):\n",
    "    ds = ds.train_test_split(test_size=0.3, seed=SEED)\n",
    "    test_and_valid = ds[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "    ds = DatasetDict({\n",
    "        \"train\": ds[\"train\"],\n",
    "        \"valid\": test_and_valid[\"train\"],\n",
    "        \"test\": test_and_valid[\"test\"],\n",
    "    })\n",
    "\n",
    "print(\"Dataset splits:\", {k: v.shape for k, v in ds.items()})\n",
    "print(\"Label names:\", LABELS.names)"
   ],
   "id": "579e08770bc5c4f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: {'train': (462701, 3)}\n",
      "Label names: ['other', 'drone']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:08:47.619443Z",
     "start_time": "2025-10-14T14:08:19.763600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64,\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "def preprocess(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    # Handle either dict or list formats\n",
    "    if isinstance(audio, dict) and \"array\" in audio:\n",
    "        waveform = torch.tensor(audio[\"array\"]).float()\n",
    "    else:\n",
    "        waveform = torch.tensor(audio).float()\n",
    "\n",
    "    # Make sure waveform is 1D\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform.mean(dim=0)  # convert stereo to mono\n",
    "\n",
    "    mel = mel_transform(waveform)\n",
    "    mel_db = db_transform(mel)\n",
    "\n",
    "    # Ensure tensor type (and contiguous memory)\n",
    "    example[\"mel\"] = mel_db.clone().detach().float()\n",
    "    return example\n",
    "\n",
    "\n",
    "ds = ds.map(preprocess)"
   ],
   "id": "4475a78c4d7eb1f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   3%|▎         | 8532/323890 [00:27<17:02, 308.31 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     26\u001B[39m     example[\u001B[33m\"\u001B[39m\u001B[33mmel\u001B[39m\u001B[33m\"\u001B[39m] = mel_db.clone().detach().float()\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m example\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m ds = \u001B[43mds\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/dataset_dict.py:954\u001B[39m, in \u001B[36mDatasetDict.map\u001B[39m\u001B[34m(self, function, with_indices, with_rank, with_split, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc, try_original_type)\u001B[39m\n\u001B[32m    951\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m with_split:\n\u001B[32m    952\u001B[39m     function = bind(function, split)\n\u001B[32m--> \u001B[39m\u001B[32m954\u001B[39m dataset_dict[split] = \u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    955\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    956\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    957\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    958\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    959\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    961\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    962\u001B[39m \u001B[43m    \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    963\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    964\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    965\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    967\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    968\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    969\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    970\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtry_original_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtry_original_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m with_split:\n\u001B[32m    976\u001B[39m     function = function.func\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/arrow_dataset.py:562\u001B[39m, in \u001B[36mtransmit_format.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    555\u001B[39m self_format = {\n\u001B[32m    556\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_type,\n\u001B[32m    557\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mformat_kwargs\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_kwargs,\n\u001B[32m    558\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_columns,\n\u001B[32m    559\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33moutput_all_columns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._output_all_columns,\n\u001B[32m    560\u001B[39m }\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m562\u001B[39m out: Union[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mDatasetDict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    563\u001B[39m datasets: \u001B[38;5;28mlist\u001B[39m[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mlist\u001B[39m(out.values()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[32m    564\u001B[39m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/arrow_dataset.py:3327\u001B[39m, in \u001B[36mDataset.map\u001B[39m\u001B[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001B[39m\n\u001B[32m   3325\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3326\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m unprocessed_kwargs \u001B[38;5;129;01min\u001B[39;00m unprocessed_kwargs_per_job:\n\u001B[32m-> \u001B[39m\u001B[32m3327\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mDataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43munprocessed_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3328\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcheck_if_shard_done\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3330\u001B[39m \u001B[38;5;66;03m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/arrow_dataset.py:3659\u001B[39m, in \u001B[36mDataset._map_single\u001B[39m\u001B[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001B[39m\n\u001B[32m   3657\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m batched:\n\u001B[32m   3658\u001B[39m     _time = time.time()\n\u001B[32m-> \u001B[39m\u001B[32m3659\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miter_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshard_iterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3660\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mupdate_data\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3661\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/arrow_dataset.py:3633\u001B[39m, in \u001B[36mDataset._map_single.<locals>.iter_outputs\u001B[39m\u001B[34m(shard_iterable)\u001B[39m\n\u001B[32m   3631\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3632\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, example \u001B[38;5;129;01min\u001B[39;00m shard_iterable:\n\u001B[32m-> \u001B[39m\u001B[32m3633\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m i, \u001B[43mapply_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/arrow_dataset.py:3556\u001B[39m, in \u001B[36mDataset._map_single.<locals>.apply_function\u001B[39m\u001B[34m(pa_inputs, indices, offset)\u001B[39m\n\u001B[32m   3554\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001B[39;00m\n\u001B[32m   3555\u001B[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001B[32m-> \u001B[39m\u001B[32m3556\u001B[39m processed_inputs = \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3557\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mpreprocess\u001B[39m\u001B[34m(example)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpreprocess\u001B[39m(example):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     audio = \u001B[43mexample\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     12\u001B[39m     \u001B[38;5;66;03m# Handle either dict or list formats\u001B[39;00m\n\u001B[32m     13\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(audio, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33marray\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m audio:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/formatting/formatting.py:285\u001B[39m, in \u001B[36mLazyDict.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m    283\u001B[39m value = \u001B[38;5;28mself\u001B[39m.data[key]\n\u001B[32m    284\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.keys_to_format:\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m     value = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28mself\u001B[39m.data[key] = value\n\u001B[32m    287\u001B[39m     \u001B[38;5;28mself\u001B[39m.keys_to_format.remove(key)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/formatting/formatting.py:380\u001B[39m, in \u001B[36mLazyRow.format\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mformat\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[32m--> \u001B[39m\u001B[32m380\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mformat_column\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m.\u001B[49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/formatting/formatting.py:464\u001B[39m, in \u001B[36mPythonFormatter.format_column\u001B[39m\u001B[34m(self, pa_table)\u001B[39m\n\u001B[32m    463\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mformat_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa.Table) -> \u001B[38;5;28mlist\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m464\u001B[39m     column = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpython_arrow_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextract_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    465\u001B[39m     column = \u001B[38;5;28mself\u001B[39m.python_features_decoder.decode_column(column, pa_table.column_names[\u001B[32m0\u001B[39m])\n\u001B[32m    466\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m column\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/datasets/formatting/formatting.py:147\u001B[39m, in \u001B[36mPythonArrowExtractor.extract_column\u001B[39m\u001B[34m(self, pa_table)\u001B[39m\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa.Table) -> \u001B[38;5;28mlist\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpa_table\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_pylist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T12:19:52.330721Z",
     "start_time": "2025-10-14T12:19:52.245603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LABELS = ds[\"train\"].features[\"label\"]\n",
    "\n",
    "# Split the \"train\" dataset into train + test\n",
    "ds_split = ds[\"train\"].train_test_split(test_size=0.3, seed=SEED)\n",
    "\n",
    "# Split the test portion into validation + test\n",
    "test_and_valid = ds_split[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "\n",
    "# Create a new DatasetDict\n",
    "ds = DatasetDict({\n",
    "    \"train\": ds_split[\"train\"],\n",
    "    \"valid\": test_and_valid[\"train\"],\n",
    "    \"test\": test_and_valid[\"test\"],\n",
    "})\n",
    "\n",
    "print(\"Dataset splits:\", {k: v.shape for k, v in ds.items()})\n",
    "print(\"Label names:\", LABELS.names)"
   ],
   "id": "e34dc4df48f18773",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: {'train': (323890, 4), 'valid': (69405, 4), 'test': (69406, 4)}\n",
      "Label names: ['other', 'drone']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:09:59.962873Z",
     "start_time": "2025-10-14T14:09:59.959635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "def collate_fn(batch):\n",
    "    SAMPLE_RATE = 16000  # set this properly for your data\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64,\n",
    "    )\n",
    "    db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for b in batch:\n",
    "        audio = b[\"audio\"]\n",
    "        if isinstance(audio, dict) and \"array\" in audio:\n",
    "            waveform = torch.tensor(audio[\"array\"]).float()\n",
    "        else:\n",
    "            waveform = torch.tensor(audio).float()\n",
    "\n",
    "        # Convert stereo → mono\n",
    "        if waveform.ndim > 1:\n",
    "            waveform = waveform.mean(dim=0)\n",
    "\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "\n",
    "        xs.append(mel_db)\n",
    "        ys.append(b[\"label\"])\n",
    "\n",
    "    # Pad to max length in batch\n",
    "    max_len = max(x.shape[-1] for x in xs)\n",
    "    xs_padded = torch.zeros((len(xs), 1, 64, max_len))\n",
    "    for i, x in enumerate(xs):\n",
    "        xs_padded[i, 0, :, :x.shape[-1]] = x\n",
    "\n",
    "    return xs_padded, torch.tensor(ys)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(ds[\"train\"], batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(ds[\"valid\"], batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(ds[\"test\"], batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, collate_fn=collate_fn)"
   ],
   "id": "de8ff4457ff413b3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T12:19:59.962629Z",
     "start_time": "2025-10-14T12:19:59.803784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioCNN2D(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = AudioCNN2D(n_classes=len(LABELS.names)).to(DEVICE)\n",
    "print(model)"
   ],
   "id": "4775d0433f04f3c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioCNN2D(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T07:41:39.657868Z",
     "start_time": "2025-10-15T07:41:39.517796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class AudioCNN2D(nn.Module):\n",
    "#     def __init__(self, n_classes):\n",
    "#         super().__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#\n",
    "#             nn.Conv2d(32, 64, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#\n",
    "#             nn.Conv2d(64, 128, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AdaptiveAvgPool2d((1, 1)),\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(128, n_classes)\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.fc(x)\n",
    "#\n",
    "# model = AudioCNN2D(n_classes=len(LABELS.names)).to(DEVICE)\n",
    "# print(model)"
   ],
   "id": "4d6724653fce3743",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioCNN2D(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T12:20:03.455620Z",
     "start_time": "2025-10-14T12:20:02.731114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "metric_acc = torchmetrics.classification.MulticlassAccuracy(num_classes=len(LABELS.names)).to(DEVICE)\n"
   ],
   "id": "9e85f434036a9344",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T12:20:06.409473Z",
     "start_time": "2025-10-14T12:20:05.196524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch[0].shape, batch[1].shape)"
   ],
   "id": "df8b384a443876c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 64, 16]) torch.Size([16])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:18:42.034063Z",
     "start_time": "2025-10-14T14:15:56.500539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_acc += metric_acc(out, y) * x.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss /= len(ds[\"train\"])\n",
    "    train_acc = train_acc / len(ds[\"train\"])\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Valid]\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_acc += metric_acc(out, y) * x.size(0)\n",
    "\n",
    "    val_loss /= len(ds[\"valid\"])\n",
    "    val_acc = val_acc / len(ds[\"valid\"])\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_2dcnn.pt\")\n",
    "        print(\"✅ Saved new best model!\")"
   ],
   "id": "1f74b30b5ae9d829",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]: 100%|██████████| 20244/20244 [02:17<00:00, 146.76it/s]\n",
      "Epoch 1/1 [Valid]: 100%|██████████| 4338/4338 [00:27<00:00, 157.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Train Loss: 0.0133 | Train Acc: 0.9959 | Val Loss: 0.0152 | Val Acc: 0.9955\n",
      "✅ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T11:34:54.613145Z",
     "start_time": "2025-10-15T11:34:54.502742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(\"best_model_2dcnn.pt\"))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        preds = out.argmax(dim=1)\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())"
   ],
   "id": "ac25a80113a8b71c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmodel\u001B[49m.load_state_dict(torch.load(\u001B[33m\"\u001B[39m\u001B[33mbest_model_2dcnn.pt\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m      2\u001B[39m model.eval()\n\u001B[32m      4\u001B[39m y_true, y_pred = [], []\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:13:36.563234Z",
     "start_time": "2025-10-14T14:13:36.423151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS.names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS.names, yticklabels=LABELS.names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Drone Recognition\")\n",
    "plt.show()\n"
   ],
   "id": "2ba0e0022e833473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       1.00      0.99      1.00     38272\n",
      "       drone       0.99      1.00      0.99     31134\n",
      "\n",
      "    accuracy                           0.99     69406\n",
      "   macro avg       0.99      0.99      0.99     69406\n",
      "weighted avg       0.99      0.99      0.99     69406\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T09:47:09.144880Z",
     "start_time": "2025-10-15T09:47:09.123428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Config ===\n",
    "SAMPLE_RATE = 16000\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Load Model ===\n",
    "model = AudioCNN2D(n_classes=len(LABELS.names)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"best_model_2dcnn.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# === Recordings list ===\n",
    "recordings = [\n",
    "    (\"/home/pierre/Downloads/B_S2_D1_092-bebop_000_.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Downloads/B_S2_D1_067-bebop_000_.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/1.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/2.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/3.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Downloads/audio.wav\", \"drone\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_whitenoise/DREGON_clean_recordings_whitenoise/60_-15_1.2.wav\", \"other\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_whitenoise/DREGON_clean_recordings_whitenoise/75_-15_2.4.wav\", \"other\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_speech/DREGON_clean_recordings_speech/45_0_1.2__3.wav\", \"other\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/test/other/1.wav\", \"other\"),\n",
    "    (\"/home/pierre/Documents/Projects/PST4/AI/data/raw/hibou_dataset/drone/2997-2997.wav\", \"drone\"),\n",
    "]\n",
    "\n",
    "# === Prediction function ===\n",
    "def predict_audio(model, path):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "\n",
    "    # Convert to mono if needed\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sr != SAMPLE_RATE:\n",
    "        resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    mel = mel_transform(waveform)\n",
    "    mel_db = db_transform(mel)\n",
    "\n",
    "    mel_db = mel_db.unsqueeze(0).to(DEVICE)  # (1, 1, n_mels, time)\n",
    "    with torch.no_grad():\n",
    "        out = model(mel_db)\n",
    "        pred_idx = out.argmax(dim=1).item()\n",
    "        pred_label = LABELS.int2str(pred_idx)\n",
    "        prob = torch.softmax(out, dim=1)[0, pred_idx].item()\n",
    "    return pred_label, prob\n",
    "\n",
    "# === Run inference for all files ===\n",
    "results = []\n",
    "\n",
    "for path, true_label in recordings:\n",
    "    if not Path(path).exists():\n",
    "        print(f\"⚠️ File not found: {path}\")\n",
    "        continue\n",
    "    pred_label, prob = predict_audio(model, path)\n",
    "    results.append({\n",
    "        \"file\": Path(path).name,\n",
    "        \"true_label\": true_label,\n",
    "        \"pred_label\": pred_label,\n",
    "        \"is_good\": true_label == pred_label,\n",
    "        \"confidence\": round(prob, 3)\n",
    "    })\n",
    "\n",
    "# === Display results as table ===\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Optional: show nicely formatted output\n",
    "display(df_results.style.background_gradient(subset=[\"confidence\"], cmap=\"Blues\"))"
   ],
   "id": "a0c78552dd9ad030",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/1.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/2.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/test/drone/3.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_whitenoise/DREGON_clean_recordings_whitenoise/60_-15_1.2.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_whitenoise/DREGON_clean_recordings_whitenoise/75_-15_2.4.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/archive(1)/DREGON_clean_recordings_speech/DREGON_clean_recordings_speech/45_0_1.2__3.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/test/other/1.wav\n",
      "⚠️ File not found: /home/pierre/Documents/Projects/PST4/AI/data/raw/hibou_dataset/drone/2997-2997.wav\n",
      "                         file true_label pred_label  is_good  confidence\n",
      "0  B_S2_D1_092-bebop_000_.wav      drone      drone     True         1.0\n",
      "1  B_S2_D1_067-bebop_000_.wav      drone      drone     True         1.0\n",
      "2                   audio.wav      drone      drone     True         1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f82e243e5d0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43ca8_row0_col4, #T_43ca8_row1_col4, #T_43ca8_row2_col4 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43ca8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_43ca8_level0_col0\" class=\"col_heading level0 col0\" >file</th>\n",
       "      <th id=\"T_43ca8_level0_col1\" class=\"col_heading level0 col1\" >true_label</th>\n",
       "      <th id=\"T_43ca8_level0_col2\" class=\"col_heading level0 col2\" >pred_label</th>\n",
       "      <th id=\"T_43ca8_level0_col3\" class=\"col_heading level0 col3\" >is_good</th>\n",
       "      <th id=\"T_43ca8_level0_col4\" class=\"col_heading level0 col4\" >confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43ca8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_43ca8_row0_col0\" class=\"data row0 col0\" >B_S2_D1_092-bebop_000_.wav</td>\n",
       "      <td id=\"T_43ca8_row0_col1\" class=\"data row0 col1\" >drone</td>\n",
       "      <td id=\"T_43ca8_row0_col2\" class=\"data row0 col2\" >drone</td>\n",
       "      <td id=\"T_43ca8_row0_col3\" class=\"data row0 col3\" >True</td>\n",
       "      <td id=\"T_43ca8_row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43ca8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_43ca8_row1_col0\" class=\"data row1 col0\" >B_S2_D1_067-bebop_000_.wav</td>\n",
       "      <td id=\"T_43ca8_row1_col1\" class=\"data row1 col1\" >drone</td>\n",
       "      <td id=\"T_43ca8_row1_col2\" class=\"data row1 col2\" >drone</td>\n",
       "      <td id=\"T_43ca8_row1_col3\" class=\"data row1 col3\" >True</td>\n",
       "      <td id=\"T_43ca8_row1_col4\" class=\"data row1 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43ca8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_43ca8_row2_col0\" class=\"data row2 col0\" >audio.wav</td>\n",
       "      <td id=\"T_43ca8_row2_col1\" class=\"data row2 col1\" >drone</td>\n",
       "      <td id=\"T_43ca8_row2_col2\" class=\"data row2 col2\" >drone</td>\n",
       "      <td id=\"T_43ca8_row2_col3\" class=\"data row2 col3\" >True</td>\n",
       "      <td id=\"T_43ca8_row2_col4\" class=\"data row2 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T07:47:47.014668Z",
     "start_time": "2025-10-15T07:47:46.291632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Collect all .wav files with true labels from subfolders ===\n",
    "base_dir = Path(\"/home/pierre/Documents/Projects/PST4/AI/data/raw/test/\")\n",
    "recordings = []\n",
    "for class_folder in [\"drone\", \"other\"]:\n",
    "    for file_path in (base_dir / class_folder).glob(\"*.wav\"):\n",
    "        recordings.append((str(file_path), class_folder))\n",
    "\n",
    "# === Run inference ===\n",
    "results = []\n",
    "for path, true_label in tqdm(recordings, desc=\"Inference\"):\n",
    "    pred_label, prob = predict_audio(model, path)\n",
    "    correct = (pred_label == true_label)\n",
    "    results.append({\n",
    "        \"file\": Path(path).name,\n",
    "        \"true_label\": true_label,\n",
    "        \"pred_label\": pred_label,\n",
    "        \"confidence\": round(prob, 3),\n",
    "        \"correct\": correct\n",
    "    })\n",
    "\n",
    "# === Create DataFrame and display results ===\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Optional: highlight correct vs incorrect\n",
    "# display(df_results.style\n",
    "#         .background_gradient(subset=[\"confidence\"], cmap=\"Blues\")\n",
    "#         .applymap(lambda v: \"background-color:#aaffaa\" if v else \"background-color:#ffaaaa\", subset=[\"correct\"])\n",
    "#        )\n",
    "\n",
    "# === Summary accuracy ===\n",
    "accuracy = df_results[\"correct\"].mean()\n",
    "print(f\"\\n✅ Global accuracy on test directory: {accuracy*100:.2f}%\")"
   ],
   "id": "b0ba65c84adc725d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/893 [00:00<?, ?it/s]/home/pierre/.local/lib/python3.13/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "Inference: 100%|██████████| 893/893 [00:00<00:00, 1247.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                file true_label pred_label  \\\n",
      "0    drone-sound-128-ytshorts.savetube.me_chunk1.wav      drone      other   \n",
      "1    drone-sound-128-ytshorts.savetube.me_chunk2.wav      drone      drone   \n",
      "2    drone-sound-128-ytshorts.savetube.me_chunk3.wav      drone      drone   \n",
      "3    drone-sound-128-ytshorts.savetube.me_chunk4.wav      drone      drone   \n",
      "4    drone-sound-128-ytshorts.savetube.me_chunk5.wav      drone      drone   \n",
      "..                                               ...        ...        ...   \n",
      "888                                   209_chunk1.wav      other      other   \n",
      "889                                   209_chunk2.wav      other      other   \n",
      "890                                   210_chunk1.wav      other      other   \n",
      "891                                   210_chunk2.wav      other      other   \n",
      "892                                   211_chunk1.wav      other      drone   \n",
      "\n",
      "     confidence  correct  \n",
      "0         1.000    False  \n",
      "1         1.000     True  \n",
      "2         0.999     True  \n",
      "3         0.999     True  \n",
      "4         0.999     True  \n",
      "..          ...      ...  \n",
      "888       0.992     True  \n",
      "889       0.998     True  \n",
      "890       1.000     True  \n",
      "891       1.000     True  \n",
      "892       0.813    False  \n",
      "\n",
      "[893 rows x 5 columns]\n",
      "\n",
      "✅ Global accuracy on test directory: 70.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T09:12:17.595605Z",
     "start_time": "2025-10-15T09:12:13.744037Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"Usernameeeeee/drone_test\", split=\"test\", download_mode=\"force_redownload\")",
   "id": "48db1b06598b1240",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 893/893 [00:00<00:00, 21765.86 examples/s]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T09:26:58.235191Z",
     "start_time": "2025-10-15T09:26:58.232657Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5f24413f62943b1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drone'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T09:47:23.988965Z",
     "start_time": "2025-10-15T09:47:23.148169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Config ===\n",
    "SAMPLE_RATE = 16000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Example placeholders – define your own\n",
    "LABELS = dataset.features[\"label\"]  # Replace with dataset.features[\"label\"]\n",
    "\n",
    "# === Unified Prediction Function ===\n",
    "def predict_audio(model, audio_input, sample_rate=None):\n",
    "    if isinstance(audio_input, str) or isinstance(audio_input, Path):\n",
    "        waveform, sr = torchaudio.load(audio_input)\n",
    "    else:\n",
    "        waveform = torch.tensor(audio_input[\"array\"]).unsqueeze(0)\n",
    "        sr = audio_input[\"sampling_rate\"]\n",
    "\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    if sr != SAMPLE_RATE:\n",
    "        waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "\n",
    "    mel = mel_transform(waveform)\n",
    "    mel_db = db_transform(mel).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(mel_db)\n",
    "        probs = torch.softmax(out, dim=1)\n",
    "        pred_idx = probs.argmax(dim=1).item()\n",
    "        pred_label = LABELS.int2str(int(pred_idx))\n",
    "        prob = probs[0, pred_idx].item()\n",
    "\n",
    "    return pred_label, prob\n",
    "\n",
    "\n",
    "# === Inference Loop ===\n",
    "results = []\n",
    "for item in tqdm(dataset, desc=\"Inference\"):\n",
    "    pred_label, prob = predict_audio(model, item[\"audio\"])\n",
    "    true_label = LABELS.int2str(int(item[\"label\"])) if \"label\" in item else None\n",
    "\n",
    "    results.append({\n",
    "        \"file\": item.get(\"filename\", \"N/A\"),\n",
    "        \"true_label\": true_label,\n",
    "        \"pred_label\": pred_label,\n",
    "        \"confidence\": round(prob, 3),\n",
    "        \"correct\": (pred_label == true_label) if true_label is not None else None\n",
    "    })\n",
    "\n",
    "\n",
    "# === Results DataFrame ===\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Optional notebook styling (omit for scripts)\n",
    "try:\n",
    "    display(df_results.style\n",
    "        .background_gradient(subset=[\"confidence\"], cmap=\"Blues\")\n",
    "        .apply(lambda col: [\"background-color:#aaffaa\" if v else \"background-color:#ffaaaa\"\n",
    "                            for v in col] if col.name == \"correct\" else col))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# === Summary Accuracy ===\n",
    "if df_results[\"correct\"].notna().any():\n",
    "    accuracy = df_results[\"correct\"].mean()\n",
    "    print(f\"\\nGlobal accuracy: {accuracy*100:.2f}%\")\n"
   ],
   "id": "acadc2f60b6688bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 893/893 [00:00<00:00, 1133.77it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Styles supplied as string must follow CSS rule formats, for example 'attr: val;'. '0_chunk1.wav' was given.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style_render.py:1920\u001B[39m, in \u001B[36mmaybe_convert_css_to_tuples\u001B[39m\u001B[34m(style)\u001B[39m\n\u001B[32m   1918\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m-> \u001B[39m\u001B[32m1920\u001B[39m         (x.split(\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m0\u001B[39m].strip(), \u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m:\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m.strip())\n\u001B[32m   1921\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m s\n\u001B[32m   1922\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m x.strip() != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1923\u001B[39m     ]\n\u001B[32m   1924\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/IPython/core/formatters.py:406\u001B[39m, in \u001B[36mBaseFormatter.__call__\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    404\u001B[39m     method = get_real_method(obj, \u001B[38;5;28mself\u001B[39m.print_method)\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    407\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    408\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style.py:405\u001B[39m, in \u001B[36mStyler._repr_html_\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    401\u001B[39m \u001B[33;03mHooks into Jupyter notebook rich display system, which calls _repr_html_ by\u001B[39;00m\n\u001B[32m    402\u001B[39m \u001B[33;03mdefault if an object is returned at the end of a cell.\u001B[39;00m\n\u001B[32m    403\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    404\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m get_option(\u001B[33m\"\u001B[39m\u001B[33mstyler.render.repr\u001B[39m\u001B[33m\"\u001B[39m) == \u001B[33m\"\u001B[39m\u001B[33mhtml\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m405\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mto_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style.py:1345\u001B[39m, in \u001B[36mStyler.to_html\u001B[39m\u001B[34m(self, buf, table_uuid, table_attributes, sparse_index, sparse_columns, bold_headers, caption, max_rows, max_columns, encoding, doctype_html, exclude_styles, **kwargs)\u001B[39m\n\u001B[32m   1342\u001B[39m     obj.set_caption(caption)\n\u001B[32m   1344\u001B[39m \u001B[38;5;66;03m# Build HTML string..\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1345\u001B[39m html = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_render_html\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1346\u001B[39m \u001B[43m    \u001B[49m\u001B[43msparse_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43msparse_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1347\u001B[39m \u001B[43m    \u001B[49m\u001B[43msparse_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43msparse_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_cols\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexclude_styles\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexclude_styles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mget_option\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstyler.render.encoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1352\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdoctype_html\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdoctype_html\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1353\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1354\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1356\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m save_to_buffer(\n\u001B[32m   1357\u001B[39m     html, buf=buf, encoding=(encoding \u001B[38;5;28;01mif\u001B[39;00m buf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m   1358\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style_render.py:204\u001B[39m, in \u001B[36mStylerRenderer._render_html\u001B[39m\u001B[34m(self, sparse_index, sparse_columns, max_rows, max_cols, **kwargs)\u001B[39m\n\u001B[32m    192\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_render_html\u001B[39m(\n\u001B[32m    193\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    194\u001B[39m     sparse_index: \u001B[38;5;28mbool\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    198\u001B[39m     **kwargs,\n\u001B[32m    199\u001B[39m ) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    200\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    201\u001B[39m \u001B[33;03m    Renders the ``Styler`` including all applied styles to HTML.\u001B[39;00m\n\u001B[32m    202\u001B[39m \u001B[33;03m    Generates a dict with necessary kwargs passed to jinja2 template.\u001B[39;00m\n\u001B[32m    203\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m204\u001B[39m     d = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_render\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparse_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_cols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m&nbsp;\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    205\u001B[39m     d.update(kwargs)\n\u001B[32m    206\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.template_html.render(\n\u001B[32m    207\u001B[39m         **d,\n\u001B[32m    208\u001B[39m         html_table_tpl=\u001B[38;5;28mself\u001B[39m.template_html_table,\n\u001B[32m    209\u001B[39m         html_style_tpl=\u001B[38;5;28mself\u001B[39m.template_html_style,\n\u001B[32m    210\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style_render.py:161\u001B[39m, in \u001B[36mStylerRenderer._render\u001B[39m\u001B[34m(self, sparse_index, sparse_columns, max_rows, max_cols, blank)\u001B[39m\n\u001B[32m    147\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_render\u001B[39m(\n\u001B[32m    148\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    149\u001B[39m     sparse_index: \u001B[38;5;28mbool\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    153\u001B[39m     blank: \u001B[38;5;28mstr\u001B[39m = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    154\u001B[39m ):\n\u001B[32m    155\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    156\u001B[39m \u001B[33;03m    Computes and applies styles and then generates the general render dicts.\u001B[39;00m\n\u001B[32m    157\u001B[39m \n\u001B[32m    158\u001B[39m \u001B[33;03m    Also extends the `ctx` and `ctx_index` attributes with those of concatenated\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[33;03m    stylers for use within `_translate_latex`\u001B[39;00m\n\u001B[32m    160\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m161\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    162\u001B[39m     dxs = []\n\u001B[32m    163\u001B[39m     ctx_len = \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style_render.py:256\u001B[39m, in \u001B[36mStylerRenderer._compute\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    254\u001B[39m r = \u001B[38;5;28mself\u001B[39m\n\u001B[32m    255\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._todo:\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     r = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style.py:1752\u001B[39m, in \u001B[36mStyler._apply\u001B[39m\u001B[34m(self, func, axis, subset, **kwargs)\u001B[39m\n\u001B[32m   1748\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(result.columns.isin(data.columns)):\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1750\u001B[39m         msg.format(\u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m, result.columns.shape, data.columns.shape)\n\u001B[32m   1751\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1752\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_ctx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1753\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style.py:1560\u001B[39m, in \u001B[36mStyler._update_ctx\u001B[39m\u001B[34m(self, attrs)\u001B[39m\n\u001B[32m   1558\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m c \u001B[38;5;129;01mor\u001B[39;00m pd.isna(c):\n\u001B[32m   1559\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1560\u001B[39m css_list = \u001B[43mmaybe_convert_css_to_tuples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1561\u001B[39m i = \u001B[38;5;28mself\u001B[39m.index.get_loc(rn)\n\u001B[32m   1562\u001B[39m \u001B[38;5;28mself\u001B[39m.ctx[(i, j)].extend(css_list)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/pandas/io/formats/style_render.py:1925\u001B[39m, in \u001B[36mmaybe_convert_css_to_tuples\u001B[39m\u001B[34m(style)\u001B[39m\n\u001B[32m   1919\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m   1920\u001B[39m             (x.split(\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m0\u001B[39m].strip(), x.split(\u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m1\u001B[39m].strip())\n\u001B[32m   1921\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m s\n\u001B[32m   1922\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m x.strip() != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1923\u001B[39m         ]\n\u001B[32m   1924\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1925\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1926\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mStyles supplied as string must follow CSS rule formats, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1927\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfor example \u001B[39m\u001B[33m'\u001B[39m\u001B[33mattr: val;\u001B[39m\u001B[33m'\u001B[39m\u001B[33m. \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstyle\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m was given.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1928\u001B[39m         )\n\u001B[32m   1929\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m style\n",
      "\u001B[31mValueError\u001B[39m: Styles supplied as string must follow CSS rule formats, for example 'attr: val;'. '0_chunk1.wav' was given."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8748139e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global accuracy: 43.00%\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
