{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Upload big datasets to HuggingFace with unstable connection\n",
    "\n",
    "Script made by GPT but working."
   ],
   "id": "113d39387ac894e1"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import login\n",
    "login(\"\") # replace with your token\n",
    "\n",
    "from huggingface_hub import HfApi, list_repo_files\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# üîß CONFIGURATION\n",
    "REPO_ID = \"Hibou-Foundation/big_ds_preprocessed_spectogram_1\"\n",
    "LOCAL_DIR = \"/mnt/drive/big_ds_1.hf\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "\n",
    "# ‚öôÔ∏è Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "def upload_directory(local_dir: str, repo_id: str, repo_type: str = \"dataset\"):\n",
    "    \"\"\"\n",
    "    Uploads all files from `local_dir` to the Hugging Face Hub repository.\n",
    "    Automatically skips already uploaded files (resumable).\n",
    "    \"\"\"\n",
    "    local_dir = Path(local_dir)\n",
    "    if not local_dir.exists():\n",
    "        raise ValueError(f\"Local directory does not exist: {local_dir}\")\n",
    "\n",
    "    print(f\"üìÇ Scanning directory: {local_dir}\")\n",
    "    files_to_upload = [p for p in local_dir.rglob(\"*\") if p.is_file()]\n",
    "    print(f\"Found {len(files_to_upload)} files to check.\")\n",
    "\n",
    "    # üß† Get list of already uploaded files\n",
    "    print(f\"üîç Fetching existing files in repo: {repo_id}\")\n",
    "    existing_files = set(list_repo_files(repo_id=repo_id, repo_type=repo_type))\n",
    "    print(f\"Repo already has {len(existing_files)} files.\")\n",
    "\n",
    "    uploaded_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for fpath in files_to_upload:\n",
    "        # Normalize path in repo (relative to base directory)\n",
    "        path_in_repo = str(fpath.relative_to(local_dir)).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if path_in_repo in existing_files:\n",
    "            print(f\"‚è© Skipping already uploaded: {path_in_repo}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"‚¨ÜÔ∏è Uploading: {path_in_repo} ...\")\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=str(fpath),\n",
    "                path_in_repo=path_in_repo,\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "            )\n",
    "            uploaded_count += 1\n",
    "            print(f\"‚úÖ Uploaded: {path_in_repo}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading {fpath}: {e}\")\n",
    "            print(\"Stopping ‚Äî rerun this script to resume.\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n‚úÖ Upload complete.\")\n",
    "    print(f\"Uploaded: {uploaded_count}, Skipped: {skipped_count}\")\n",
    "\n",
    "upload_directory(LOCAL_DIR, REPO_ID, REPO_TYPE)"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
