{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import ClassLabel, Audio, DatasetDict\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Audio as DisplayAudio\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "NUM_PROC = 6\n",
    "SAMPLING_RATE = 16000\n",
    "CHUNK_DURATION = 0.5\n",
    "BATCH_SIZE = 32\n",
    "THRESHOLD_AUGMENTATION = 0.5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Loading DS\")\n",
    "# Load dataset\n",
    "DS = load_dataset(\"n1coc4cola/maotouying\")\n",
    "print(len(DS))\n",
    "DS_train = DS[\"train\"]"
   ],
   "id": "f50c8d27f32ebe05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Shuffling\")\n",
    "# Take only n% of the dataset\n",
    "n = 1\n",
    "DS_train_shuffled = DS_train.shuffle(seed=SEED).select(range(int(n * len(DS_train))))"
   ],
   "id": "9ebeb9471a5bda96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_test = DS_train_shuffled.train_test_split(test_size=0.2, seed=SEED)\n",
    "test_val = train_test[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"val\": test_val[\"train\"],\n",
    "    \"test\": test_val[\"test\"],\n",
    "})"
   ],
   "id": "739e03a487aaf0c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cast to 16khz\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))"
   ],
   "id": "84d363c93d163c1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def noise_injection(data, noise_factor):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    # Cast back to the same data type\n",
    "    augmented_data = augmented_data.astype(type(data[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def change_pitch(data, sampling_rate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "\n",
    "def time_stretch(data, stretch_factor):\n",
    "    return librosa.effects.time_stretch(data, rate=stretch_factor)\n",
    "\n",
    "def frequency_mask(data, mask_width=10):\n",
    "    stft = librosa.stft(data)\n",
    "    freq_bins = stft.shape[0]\n",
    "    f0 = np.random.randint(0, freq_bins - mask_width)\n",
    "    stft[f0:f0+mask_width, :] = 0\n",
    "    return librosa.istft(stft)\n",
    "\n",
    "def time_mask(data, mask_width=10):\n",
    "    d = data.copy()\n",
    "    t0 = np.random.randint(0, len(d) - mask_width)\n",
    "    d[t0:t0+mask_width] = 0\n",
    "    return d\n",
    "\n",
    "def dynamic_range_compression(data, threshold, ratio):\n",
    "    # Simple compression: reduce amplitude above threshold\n",
    "    compressed = data.copy()\n",
    "    compressed[np.abs(data) > threshold] = threshold + (compressed[np.abs(data) > threshold] - threshold) / ratio\n",
    "    return compressed"
   ],
   "id": "e81b9794161c9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Size of dataset: {len(dataset)}\")\n",
    "print(f\"Size of splits: train={len(dataset['train'])}, val={len(dataset['val'])}, test={len(dataset['test'])}\")"
   ],
   "id": "88683268461f5e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_audio_into_chunks(audio_array, chunk_duration=CHUNK_DURATION, sampling_rate=SAMPLING_RATE):\n",
    "    samples_per_chunk = int(chunk_duration * sampling_rate)\n",
    "    num_chunks = audio_array.shape[-1] // samples_per_chunk\n",
    "\n",
    "    # Only split into full chunks, no padding\n",
    "    chunks = [audio_array[i * samples_per_chunk:(i + 1) * samples_per_chunk]\n",
    "              for i in range(num_chunks)]\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def chunk_audio_batch(batch):\n",
    "    # Process by batch to allow multi processing\n",
    "    all_audios = []\n",
    "    all_sampling_rates = []\n",
    "    all_labels = []\n",
    "\n",
    "    for audio, label in zip(batch[\"audio\"], batch[\"label\"]):\n",
    "        audio_array = audio[\"array\"]\n",
    "        sampling_rate = audio[\"sampling_rate\"]\n",
    "        audio_array = torch.tensor(audio_array).float()\n",
    "        chunks = split_audio_into_chunks(audio_array)\n",
    "\n",
    "        all_audios.extend([chunk.numpy() for chunk in chunks])\n",
    "        all_sampling_rates.extend([sampling_rate] * len(chunks))\n",
    "        all_labels.extend([label] * len(chunks))\n",
    "\n",
    "    return {\n",
    "        \"audio\": all_audios,\n",
    "        \"label\": all_labels,\n",
    "    }\n",
    "\n",
    "\n",
    "chunked_dataset = DatasetDict()\n",
    "for split in dataset.keys():\n",
    "    print(f\"Chunking split: {split}, original length: {len(dataset[split])}\")\n",
    "    chunked_split = dataset[split].map(\n",
    "        chunk_audio_batch,\n",
    "        batched=True,\n",
    "        num_proc=NUM_PROC,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        remove_columns=dataset[split].column_names,\n",
    "    )\n",
    "    print(f\"Generated split {split} length, {len(chunked_split)}\")\n",
    "    chunked_dataset[split] = chunked_split"
   ],
   "id": "46067d4009f91aca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def augmente_batch(batch):\n",
    "    rng = np.random.default_rng()\n",
    "    all_audios = []\n",
    "    all_labels = []\n",
    "\n",
    "    for audio, label in zip(batch[\"audio\"], batch[\"label\"]):\n",
    "        all_audios.append(audio)\n",
    "        all_labels.append(label)\n",
    "\n",
    "        augmented_audio = None\n",
    "        if rng.random() > THRESHOLD_AUGMENTATION:\n",
    "            r = rng.random()\n",
    "            data = np.array(audio)\n",
    "            if r < 0.20:\n",
    "                augmented_audio = noise_injection(data, noise_factor=0.05)\n",
    "            elif r < 0.40:\n",
    "                augmented_audio = change_pitch(data, sampling_rate=SAMPLING_RATE, pitch_factor=2)\n",
    "            elif r < 0.60:\n",
    "                augmented_audio = time_stretch(data, stretch_factor=1.1)\n",
    "            elif r < 0.80:\n",
    "                augmented_audio = dynamic_range_compression(data, threshold=0.05, ratio=1.0)\n",
    "            else:\n",
    "                augmented_audio = frequency_mask(data, mask_width=20)\n",
    "\n",
    "            all_audios.append(augmented_audio)\n",
    "            all_labels.append(label)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"audio\": all_audios,\n",
    "        \"label\": all_labels,\n",
    "    }\n",
    "\n",
    "augmented_dataset = DatasetDict()\n",
    "for split in chunked_dataset.keys():\n",
    "    print(f\"Augmenting split: {split}, length before: {len(chunked_dataset[split])}\")\n",
    "    augmented_split = chunked_dataset[split].map(\n",
    "        augmente_batch,\n",
    "        batched=True,\n",
    "        num_proc=NUM_PROC,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        remove_columns=chunked_dataset[split].column_names,\n",
    "    )\n",
    "    print(f\"Length after: {len(augmented_split)}\")\n",
    "    augmented_dataset[split] = augmented_split\n"
   ],
   "id": "5dcd316ee675e42a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Audio transforms for linear spectrogram\n",
    "# -----------------------------\n",
    "def convert_to_linear_spectrogram(batch):\n",
    "    all_linear_db = []\n",
    "    all_labels = []\n",
    "\n",
    "    for audio, label in zip(batch[\"audio\"], batch[\"label\"]):\n",
    "        data = np.array(audio)\n",
    "        # Compute STFT\n",
    "        stft = librosa.stft(data, n_fft=2048, hop_length=512)\n",
    "\n",
    "        # Compute magnitude\n",
    "        magnitude = np.abs(stft)\n",
    "\n",
    "        # Convert to dB\n",
    "        linear_db = librosa.amplitude_to_db(magnitude, ref=np.max)\n",
    "\n",
    "        all_linear_db.append(linear_db)\n",
    "        all_labels.append(label)\n",
    "\n",
    "    return {\n",
    "        \"audio\": all_linear_db,\n",
    "        \"label\": all_labels,\n",
    "    }\n",
    "\n",
    "spectrogram_dataset = DatasetDict()\n",
    "for split in augmented_dataset.keys():\n",
    "    print(f\"Converting to spectrogram split: {split}\")\n",
    "    spectrogram_split = augmented_dataset[split].map(\n",
    "        convert_to_linear_spectrogram,\n",
    "        batched=True,\n",
    "        num_proc=NUM_PROC,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        remove_columns=augmented_dataset[split].column_names,\n",
    "    )\n",
    "    spectrogram_dataset[split] = spectrogram_split\n"
   ],
   "id": "284f5be619efd41f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spectrogram_dataset.save_to_disk(\"./big_ds_1.hf\")",
   "id": "ea75e1f1149f2f8a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
